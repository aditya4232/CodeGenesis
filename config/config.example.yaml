# MemoRAG ULTRA Configuration

# LM Studio Settings
lm_studio:
  base_url: "http://localhost:1234/v1"
  model_name: "phi-3-mini-4k-instruct"  # Change to your downloaded model
  temperature: 0.7
  max_tokens: 2048
  timeout: 60

# Embedding Model
embeddings:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  device: "cpu"
  batch_size: 32

# Vector Index
vector_index:
  type: "faiss"
  dimension: 384
  index_type: "IndexFlatL2"  # or "IndexIVFFlat" for larger datasets
  nlist: 100  # for IVF indexes

# Knowledge Graph
knowledge_graph:
  enable_temporal: true
  confidence_threshold: 0.6
  max_hops: 3
  community_detection: true

# RAG Settings
rag:
  chunk_size: 512
  chunk_overlap: 50
  top_k_speed: 5
  top_k_deep: 10
  mode_selection_threshold: 0.7  # complexity score threshold for deep mode

# Continual Learning
memory:
  importance_decay: 0.95
  consolidation_interval: 100  # queries
  pruning_threshold: 0.1
  max_memory_items: 10000

# Semantic Cache
cache:
  enable: true
  redis_url: "redis://localhost:6379"
  similarity_threshold: 0.9
  ttl: 3600  # seconds

# Fact-Checking
fact_checking:
  enable: true
  external_kb:
    wikipedia: true
    pubmed: false  # requires API key
    arxiv: false
  credibility_weight: 0.3

# Active Learning
active_learning:
  enable: true
  suggestion_count: 5
  uncertainty_threshold: 0.5

# Monitoring
monitoring:
  enable: true
  metrics_interval: 60  # seconds
  anomaly_detection: true

# Multi-Modal
multimodal:
  ocr:
    engine: "tesseract"  # or "paddleocr"
    languages: ["eng"]
  audio:
    model: "openai/whisper-base"
    device: "cpu"
  vision:
    enable: true

# Database
database:
  type: "sqlite"
  path: "data/memorag.db"
  pool_size: 10

# Storage Paths
paths:
  documents: "data/documents"
  indexes: "data/indexes"
  cache: "data/cache"
  logs: "data/logs"

# Resource Limits
limits:
  max_document_size_mb: 50
  max_documents: 10000
  max_concurrent_queries: 10
  memory_limit_gb: 6

# API Settings
api:
  host: "0.0.0.0"
  port: 8000
  cors_origins: ["http://localhost:5173", "http://localhost:3000"]
  rate_limit: 100  # requests per minute

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "json"
  file: "data/logs/memorag.log"

# Feature Flags
features:
  enable_agents: true
  enable_self_healing: true
  enable_collaboration: false  # multi-user (future)
  enable_gpu: false  # set to true if GPU available
